{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the datasets provided by the gan_t2i module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import from the module `gan_t2i.datasets.DatasetFactory` the `DataFactory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "module_path = os.path.join(os.getcwd(), '../src')\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Use the DatasetFactory to load the dataset\n",
    "import gan_t2i.datasets.DatasetFactory as DatasetFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the datasets you can choose how to store it: in memory or by creading a h5 file. The default storing modality, the one that we recommend, is HDF5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each field of the dataset is made up by the image as `PIL` image, the caption (the description of the image) as `string` and the class of the image as `integer` number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can transform the dataset fields indipendently, this means that you can define a transformation for the image one for the caption and another one for the class.\n",
    "\n",
    "For example we can convert the images in tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset (e.g. the flower dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data folder where to store the dataset\n",
    "data_folder = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "# Create the dataset\n",
    "flower_dataset = DatasetFactory.Flowers(data_folder, transform_img=transform_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the images in the laoded dataset have the resize dimension (in this case 64 x 64 x 3 color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (img, cap, class_number) in enumerate(flower_dataset):\n",
    "    assert img.numpy().shape == (3, 64, 64)  # check the shape of the images\n",
    "print(\"All images have the right shape!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the dataset length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset length: \", len(flower_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some images of the dataset with the corresponding caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = [random.randint(0, len(flower_dataset) - 1) for _ in range(4)]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for i, d_index in enumerate(random_indexes):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(transforms.ToPILImage()(flower_dataset[d_index][0]))\n",
    "    plt.title(f\"image {i+1} | class: {flower_dataset[d_index][2]}\")    \n",
    "    print(f\"image {i+1} caption: {flower_dataset[d_index][1]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birds Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the birds dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data folder where to store the dataset\n",
    "data_folder = os.path.join(os.getcwd(), '../data')\n",
    "\n",
    "# Create the dataset\n",
    "birds_dataset = DatasetFactory.Birds(data_folder, resize=(64, 64), transform_img=transform_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (img, cap, class_number) in enumerate(birds_dataset):\n",
    "    assert img.numpy().shape == (3, 64, 64)  # check the shape of the images\n",
    "print(\"All images have the right shape!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dataset length: \", len(birds_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = [random.randint(0, len(birds_dataset) - 1) for _ in range(4)]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for i, d_index in enumerate(random_indexes):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(transforms.ToPILImage()(birds_dataset[d_index][0]))\n",
    "    plt.title(f\"image {i+1} | class: {birds_dataset[d_index][2]}\")    \n",
    "    print(f\"image {i+1} caption: {birds_dataset[d_index][1]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Torch DataLoader with the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the provided `DataLoader` of pytorch to load, shuffle, divide into batches, etc... the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_dataloader = DataLoader(flower_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "batch_numbers = 0\n",
    "for images, captions, class_number in flowers_dataloader:\n",
    "    batch_numbers += 1\n",
    "print(\"Number of batches: \", batch_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_dataloader = DataLoader(birds_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "batch_numbers = 0\n",
    "for images, captions, class_number in birds_dataloader:\n",
    "    batch_numbers += 1\n",
    "print(\"Number of batches: \", batch_numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
